{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import ensemble\n",
    "from faker import Faker as fake\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-19.12.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting typing-extensions>=3.10.0.1; python_version <= \"3.8\"\n",
      "  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\python\\lib\\site-packages (from faker) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python\\lib\\site-packages (from python-dateutil>=2.4->faker) (1.15.0)\n",
      "Installing collected packages: typing-extensions, faker\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "Successfully installed faker-19.12.0 typing-extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    path = 'cardio_train.csv'\n",
    "    df = pd.read_csv(path,delimiter=\";\")\n",
    "    x1=df.loc[:,df.columns!='cardio']\n",
    "    y1=df.loc[:,'cardio']\n",
    "    # Resample the training set to balance the classes\n",
    "    oversampler = SMOTE(random_state=30)\n",
    "    X_train_resampled, Y_train_resampled = oversampler.fit_resample(x1, y1)\n",
    "    return X_train_resampled, Y_train_resampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rf(X_train_resampled, Y_train_resampled, training_size=0.10):\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X_train_resampled, Y_train_resampled, train_size=training_size, random_state=5)\n",
    "    model = ensemble.RandomForestClassifier()\n",
    "    model.fit(X_train_resampled, np.ravel(Y_train_resampled))\n",
    "    y_pred_rfc = model.predict(xtest)\n",
    "    accuracy = round(accuracy_score(ytest,y_pred_rfc)*100,3)\n",
    "    return accuracy, ytest, y_pred_rfc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "   Training Size  Accuracy\n",
      "0           0.05     100.0\n",
      "2\n",
      "   Training Size  Accuracy\n",
      "0           0.05     100.0\n",
      "1           0.10     100.0\n",
      "3\n",
      "   Training Size  Accuracy\n",
      "0           0.05   100.000\n",
      "1           0.10   100.000\n",
      "2           0.15    99.998\n",
      "4\n",
      "   Training Size  Accuracy\n",
      "0           0.05   100.000\n",
      "1           0.10   100.000\n",
      "2           0.15    99.998\n",
      "3           0.20   100.000\n",
      "5\n",
      "   Training Size  Accuracy\n",
      "0           0.05   100.000\n",
      "1           0.10   100.000\n",
      "2           0.15    99.998\n",
      "3           0.20   100.000\n",
      "4           0.25   100.000\n",
      "6\n",
      "   Training Size  Accuracy\n",
      "0           0.05   100.000\n",
      "1           0.10   100.000\n",
      "2           0.15    99.998\n",
      "3           0.20   100.000\n",
      "4           0.25   100.000\n",
      "5           0.30    99.998\n",
      "7\n",
      "   Training Size  Accuracy\n",
      "0           0.05   100.000\n",
      "1           0.10   100.000\n",
      "2           0.15    99.998\n",
      "3           0.20   100.000\n",
      "4           0.25   100.000\n",
      "5           0.30    99.998\n",
      "6           0.35   100.000\n",
      "8\n",
      "   Training Size  Accuracy\n",
      "0           0.05   100.000\n",
      "1           0.10   100.000\n",
      "2           0.15    99.998\n",
      "3           0.20   100.000\n",
      "4           0.25   100.000\n",
      "5           0.30    99.998\n",
      "6           0.35   100.000\n",
      "7           0.40   100.000\n",
      "9\n",
      "   Training Size  Accuracy\n",
      "0           0.05   100.000\n",
      "1           0.10   100.000\n",
      "2           0.15    99.998\n",
      "3           0.20   100.000\n",
      "4           0.25   100.000\n",
      "5           0.30    99.998\n",
      "6           0.35   100.000\n",
      "7           0.40   100.000\n",
      "8           0.45   100.000\n",
      "10\n",
      "   Training Size  Accuracy\n",
      "0           0.05   100.000\n",
      "1           0.10   100.000\n",
      "2           0.15    99.998\n",
      "3           0.20   100.000\n",
      "4           0.25   100.000\n",
      "5           0.30    99.998\n",
      "6           0.35   100.000\n",
      "7           0.40   100.000\n",
      "8           0.45   100.000\n",
      "9           0.50    99.994\n",
      "11\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "12\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "11           0.60    99.989\n",
      "13\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "11           0.60    99.989\n",
      "12           0.65   100.000\n",
      "14\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "11           0.60    99.989\n",
      "12           0.65   100.000\n",
      "13           0.70   100.000\n",
      "15\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "11           0.60    99.989\n",
      "12           0.65   100.000\n",
      "13           0.70   100.000\n",
      "14           0.75   100.000\n",
      "16\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "11           0.60    99.989\n",
      "12           0.65   100.000\n",
      "13           0.70   100.000\n",
      "14           0.75   100.000\n",
      "15           0.80   100.000\n",
      "17\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "11           0.60    99.989\n",
      "12           0.65   100.000\n",
      "13           0.70   100.000\n",
      "14           0.75   100.000\n",
      "15           0.80   100.000\n",
      "16           0.85   100.000\n",
      "18\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "11           0.60    99.989\n",
      "12           0.65   100.000\n",
      "13           0.70   100.000\n",
      "14           0.75   100.000\n",
      "15           0.80   100.000\n",
      "16           0.85   100.000\n",
      "17           0.90   100.000\n",
      "19\n",
      "    Training Size  Accuracy\n",
      "0            0.05   100.000\n",
      "1            0.10   100.000\n",
      "2            0.15    99.998\n",
      "3            0.20   100.000\n",
      "4            0.25   100.000\n",
      "5            0.30    99.998\n",
      "6            0.35   100.000\n",
      "7            0.40   100.000\n",
      "8            0.45   100.000\n",
      "9            0.50    99.994\n",
      "10           0.55   100.000\n",
      "11           0.60    99.989\n",
      "12           0.65   100.000\n",
      "13           0.70   100.000\n",
      "14           0.75   100.000\n",
      "15           0.80   100.000\n",
      "16           0.85   100.000\n",
      "17           0.90   100.000\n",
      "18           0.95   100.000\n"
     ]
    }
   ],
   "source": [
    "X_train_resampled, Y_train_resampled = read_data()\n",
    "columns = [\"Training Size\", \"Accuracy\"]\n",
    "scores_df = pd.DataFrame(columns=columns)\n",
    "#fig, axes = plt.subplots(5, 4, figsize=(12, 15))\n",
    "\n",
    "\n",
    "for ts in range(1, 20, 1):\n",
    "    ts_rounded = round(ts * 0.05,2)\n",
    "    print(ts)\n",
    "    acc_rf, ytest_rf, predict_rf = train_rf(X_train_resampled, Y_train_resampled, ts_rounded)\n",
    "    scores_df = pd.concat([scores_df, pd.DataFrame({\"Training Size\": [ts_rounded], \"Accuracy\": [acc_rf]})], ignore_index=True)\n",
    "    print(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70042\n",
      "70042\n",
      "1    35021\n",
      "0    35021\n",
      "Name: cardio, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_resampled))\n",
    "print(len(Y_train_resampled))\n",
    "#print(y1.value_counts())\n",
    "print(Y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    35021\n",
      "1    34979\n",
      "Name: cardio, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "path = 'cardio_train.csv'\n",
    "df = pd.read_csv(path,delimiter=\";\")\n",
    "x1=df.loc[:,df.columns!='cardio']\n",
    "y1=df.loc[:,'cardio']\n",
    "\n",
    "print(y1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Print the metrics\n",
    "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
    "precision = metrics.precision_score(Y_test, Y_pred)\n",
    "recall = metrics.recall_score(Y_test, Y_pred)\n",
    "f1 = metrics.f1_score(Y_test, y_pred_dtc)\n",
    "cm = confusion_matrix(Y_test, y_pred_dtc)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_test, y_pred_dtc))\n",
    "print(\"Precision:\", metrics.precision_score(Y_test, y_pred_dtc))\n",
    "print(\"Recall:\", metrics.recall_score(Y_test, y_pred_dtc))\n",
    "print(\"F1 score:\", metrics.f1_score(Y_test, y_pred_dtc))\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=False, yticklabels=False, cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (80, 40))\n",
    "tree.plot_tree(dtc, filled = 'true', fontsize = 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
